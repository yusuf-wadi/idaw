{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import speech_recognition as sr\n",
        "import pyttsx3\n",
        "import openai\n",
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from difflib import SequenceMatcher\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\thewa\\AppData\\Local\\Temp\\ipykernel_2212\\1448262854.py:17: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "openai.api_key_path = \"key.txt\"\n",
        "cur_model = \"text-davinci-002\"\n",
        "img = [\"image\", \"picture\", \"photo\", \"landscape\", \"painting\", \"drawing\", \"art\"]\n",
        "\n",
        "\n",
        "# Define Brave path\n",
        "brave_path = \"C:/Program Files/BraveSoftware/Brave-Browser-Nightly/Application/brave.exe\"\n",
        "options = webdriver.ChromeOptions()\n",
        "options.binary_location = brave_path\n",
        "\n",
        "# set dl options\n",
        "prefs = {\"download.default_directory\": \"C:/Users/thewa/Desktop/projects/computational_neuroscience/AI_ML/projects/mun_ching/crawlers/content\"}\n",
        "\n",
        "options.add_experimental_option(\"prefs\", prefs)\n",
        "\n",
        "# Create new automated instance of Brave\n",
        "driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
        "driver.minimize_window()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "def callGPT(prompt):\n",
        "\n",
        "        completion = openai.Completion.create(\n",
        "                    model=cur_model,\n",
        "                    prompt=prompt,\n",
        "                    temperature=0,\n",
        "                    frequency_penalty=0.5,\n",
        "                    max_tokens=20,\n",
        "\n",
        "\n",
        "                )\n",
        "        \n",
        "        return completion.choices[0].text\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def getGame(response):\n",
        "    \n",
        "    s = soundex.getInstance()\n",
        "    URL = \"https://steamcommunity.com/id/yusufwadi/games?tab=all&xml=1\"\n",
        "    data = requests.get(url=URL)\n",
        "    soup = bs(data.text, 'xml')\n",
        "    names = soup.find_all(\"name\")\n",
        "    \n",
        "    for name in names:\n",
        "        if (SequenceMatcher(a=response,b=name.text).ratio()):\n",
        "            #print(name.text)\n",
        "            #print(name.parent.find(\"appID\").text)\n",
        "            return name.parent.find(\"appID\").text\n",
        "    \n",
        "    print(\"Game not found\")\n",
        "\n",
        "    #print(\"hello\")\n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "    \n",
        "# From here\n",
        "def qCommand(x):\n",
        "\n",
        "    x = x.lower()\n",
        "    r2 = sr.Recognizer()\n",
        "   \n",
        "    if 'youtube' in x:\n",
        "    \n",
        "           \n",
        "            driver.get('https://www.youtube.com/')\n",
        "\n",
        "            with sr.Microphone() as source:\n",
        "                engine.say(\"What do you want to see?\")\n",
        "                engine.runAndWait()\n",
        "                print('')\n",
        "                audio = r2.listen(source)\n",
        "                keyword = r2.recognize_google(audio)\n",
        "                print(keyword)\n",
        "      \n",
        "\n",
        "            YOUR_PROMPT = \"Extract a search query from the following prompt: \" + '\"' + keyword + '\"'\n",
        " \n",
        "            response = callGPT(YOUR_PROMPT)\n",
        "\n",
        "\n",
        "\n",
        "            elem = driver.find_element('xpath', '//input[@id=\"search\"]')\n",
        "            elem.click()\n",
        "            elem.send_keys(response, Keys.RETURN)\n",
        "\n",
        "                \n",
        "\n",
        "            try:\n",
        "                get = r2.recognize_google(audio)\n",
        "                print(get)\n",
        "            except sr.UnknownValueError:\n",
        "                print('Client side error')\n",
        "            except sr.RequestError:\n",
        "                print('Error on my side')\n",
        "\n",
        "            # Till here is the code to run a YouTube vid\n",
        "    elif 'google' in x:\n",
        "           \n",
        "            driver.get('https://www.google.com/')\n",
        "\n",
        "            with sr.Microphone() as source:\n",
        "                engine.say(\"What do you want to search for?\")\n",
        "                engine.runAndWait()\n",
        "                print('')\n",
        "                audio = r2.listen(source,timeout=5)\n",
        "                keyword = r2.recognize_google(audio)\n",
        "                print(keyword)\n",
        "            YOUR_PROMPT = \"Extract a search query from the following prompt: \" + '\"' + keyword + '\"'\n",
        "\n",
        "            completion = openai.Completion.create(\n",
        "                model=cur_model,\n",
        "                prompt=YOUR_PROMPT,\n",
        "                temperature=0,\n",
        "                frequency_penalty=0.5,\n",
        "                max_tokens=20,\n",
        "\n",
        "\n",
        "            )\n",
        "\n",
        "            response = callGPT(YOUR_PROMPT)\n",
        "\n",
        "\n",
        "\n",
        "            elem = driver.find_element('xpath', '//input[@class=\"gLFyf gsfi\"]')\n",
        "            elem.click()\n",
        "            elem.send_keys(response, Keys.RETURN)\n",
        "            \n",
        "            # if img in x:\n",
        "\n",
        "                \n",
        "    elif 'play' in x:\n",
        "\n",
        "        print(x)\n",
        "        \n",
        "        prompt = \"Extract the name of the game from the prompt: \" + x\n",
        "\n",
        "        response = callGPT(prompt)\n",
        "\n",
        "        gameID = getGame(response)\n",
        "\n",
        "        driver.get(\"steam://rungameid/\" + gameID)\n",
        "\n",
        "    else:\n",
        "            print(\"command not recognized\")\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listening...\n",
            "\n",
            "I want to see a video about best Jake combos\n",
            "I want to see a video about best Jake combos\n"
          ]
        }
      ],
      "source": [
        "\n",
        "r1 = sr.Recognizer()\n",
        "r2 = sr.Recognizer()\n",
        "r3 = sr.Recognizer()\n",
        "\n",
        "engine = pyttsx3.init()\n",
        "voices = engine.getProperty('voices')\n",
        "engine.setProperty('voice', voices[0].id)\n",
        "\n",
        "with sr.Microphone() as source:\n",
        "    print('Listening...')\n",
        "    engine.say(\"Hello. I am Idaw. What can I do for you today?\")\n",
        "    engine.runAndWait()\n",
        "    audio = r3.listen(source)\n",
        "\n",
        "qCommand(r2.recognize_google(audio))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Voice Assist"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aa66cff0e5ae32d77d72462d7ae697218f766852b9c548e64c3db10232013247"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
