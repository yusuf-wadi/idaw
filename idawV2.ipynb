{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import whisper\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from difflib import SequenceMatcher\n",
    "import subprocess\n",
    "import random\n",
    "import openai\n",
    "import re\n",
    "from time import sleep\n",
    "import pyautogui as pg\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created\": 1662585223,\n",
      "  \"id\": \"curie:ft-valley:intents-v3-2022-09-07-21-13-43\",\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"valley\",\n",
      "  \"parent\": \"curie:2020-05-03\",\n",
      "  \"permission\": [\n",
      "    {\n",
      "      \"allow_create_engine\": true,\n",
      "      \"allow_fine_tuning\": true,\n",
      "      \"allow_logprobs\": true,\n",
      "      \"allow_sampling\": true,\n",
      "      \"allow_search_indices\": false,\n",
      "      \"allow_view\": true,\n",
      "      \"created\": 1662585223,\n",
      "      \"group\": null,\n",
      "      \"id\": \"snapperm-UUGBlCrhG5UfCifDheqfhshO\",\n",
      "      \"is_blocking\": false,\n",
      "      \"object\": \"model_permission\",\n",
      "      \"organization\": \"org-Hb0we8IDMAPPvwftmdXgDTvf\"\n",
      "    }\n",
      "  ],\n",
      "  \"root\": \"curie:2020-05-03\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "web = False\n",
    "steam_name = \"yusufwadi\"\n",
    "openai.api_key_path = \"key.txt\"\n",
    "cur_model = \"text-davinci-002\"\n",
    "intents_model = \"curie:ft-valley:intents-v3-2022-09-07-21-13-43\"\n",
    "print(openai.Model.retrieve(intents_model))\n",
    "a_model = whisper.load_model(\"base\")\n",
    "\n",
    "r3 = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class person:\n",
    "    name = ''\n",
    "\n",
    "    def setName(self, name):\n",
    "        self.name = name\n",
    "\n",
    "\n",
    "person_obj = person()\n",
    "person_obj.name = \"Wadi\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new automated instance of Brave\n",
    "def runWeb(web):\n",
    "    if web == False:\n",
    "        # Define Brave path\n",
    "        web = True\n",
    "        brave_path = \"C:/Program Files/BraveSoftware/Brave-Browser-Nightly/Application/brave.exe\"\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.binary_location = brave_path\n",
    "\n",
    "        # set dl options\n",
    "        #prefs = {\"download.default_directory\": \"C:/Users/thewa/Desktop/\"}\n",
    "\n",
    "        #options.add_experimental_option(\"prefs\", prefs)\n",
    "        options.add_experimental_option(\"detach\", True)\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "        return driver\n",
    "    else:\n",
    "        body = driver.find_element(\"tag name\", \"body\")\n",
    "        body.send_keys(Keys.CONTROL + 't')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def speak(audio_string):\n",
    "    engine.say(audio_string)\n",
    "    engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listenBack(tts=\"\"):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def listening(tts=\"\"):\n",
    "    with sr.Microphone() as source:\n",
    "        voice=\"\"\n",
    "        \n",
    "        if tts != \"\":\n",
    "            speak(tts)\n",
    "        \n",
    "        try:\n",
    "            speak(\"Listening...\")\n",
    "            audio = r3.listen(source,timeout=10,phrase_time_limit=4)\n",
    "        except sr.WaitTimeoutError:\n",
    "            listenBack = r3.listen_in_background(source,listenBack)   \n",
    "            \n",
    "        try:\n",
    "            voice = r3.recognize_google(audio)  # convert audio to text\n",
    "            speak(f\"Processing {voice}...\")\n",
    "        except sr.UnknownValueError:  # error: recognizer does not understand\n",
    "            print(\"...\")\n",
    "\n",
    "        except sr.RequestError:\n",
    "            speak('Sorry, the service is down')\n",
    "\n",
    "        print(f\">> {voice.lower()}\")\n",
    "        return voice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def callGPT(prompt, tokens, model=cur_model):\n",
    "\n",
    "    completion = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        frequency_penalty=0.5,\n",
    "        max_tokens=tokens,\n",
    "\n",
    "    )\n",
    "\n",
    "    response = \" \".join(re.findall(\"[a-zA-Z]+\", completion.choices[0].text))\n",
    "    response = str(response)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smartListen(command):\n",
    "    r3 = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        audio = r3.listen(source)\n",
    "        if audio != sr.UnknownValueError:\n",
    "            speak(\"Processing...\")\n",
    "        try:\n",
    "            keyword = r3.recognize_google(audio)  # convert audio to text\n",
    "        except sr.UnknownValueError:  # error: recognizer does not understand\n",
    "            print(\"...\")\n",
    "        except sr.RequestError:\n",
    "            speak('Sorry, the service is down')\n",
    "\n",
    "        print(f\">> {keyword.lower()}\")\n",
    "\n",
    "        YOUR_PROMPT = \" \" + '\"' + keyword + '\"'\n",
    "\n",
    "        response = callGPT(YOUR_PROMPT, 20)\n",
    "        print(response)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smartSearch(listen=False, keyword=\"\"):\n",
    "    if listen == True:\n",
    "        r3 = sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            audio = r3.listen(source, phrase_time_limit=4)\n",
    "            keyword = r3.recognize_google(audio)\n",
    "    else:\n",
    "\n",
    "        YOUR_PROMPT = f\"Extract a search query from the following prompt: '{keyword}'\"\n",
    "\n",
    "        response = callGPT(YOUR_PROMPT, 20)\n",
    "\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getGame(response):\n",
    "\n",
    "    URL = \"https://steamcommunity.com/id/\" + steam_name + \"/games?tab=all&xml=1\"\n",
    "    data = requests.get(url=URL)\n",
    "    soup = bs(data.text, 'xml')\n",
    "    names = soup.find_all(\"name\")\n",
    "    response = response.lower()\n",
    "\n",
    "    for name in names:\n",
    "\n",
    "        if ((SequenceMatcher(a=response, b=name.text.lower()).ratio()) > 0.70):\n",
    "            engine.say(\"Now launching... \" + name.text)\n",
    "            engine.runAndWait()\n",
    "            print(name.text)\n",
    "            print(name.parent.find(\"appID\").text)\n",
    "\n",
    "            return name.parent.find(\"appID\").text\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# command functions\n",
    "\n",
    "\n",
    "def greetings():\n",
    "    greetings = [f\"hey, how can I help you {person_obj.name}\", f\"hey, what's up? {person_obj.name}\",\n",
    "                 f\"I'm listening {person_obj.name}\", f\"how can I help you? {person_obj.name}\", f\"hello {person_obj.name}\"]\n",
    "    greet = greetings[random.randint(0, len(greetings)-1)]\n",
    "    speak(greet)\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def goodbye():\n",
    "\n",
    "    speak(\"going offline\")\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def play(command):\n",
    "\n",
    "    prompt = f\"Extract the name of the game from the prompt: {command}\"\n",
    "\n",
    "    response = callGPT(prompt, 20)\n",
    "\n",
    "    gameID = getGame(response)\n",
    "    try:\n",
    "        subprocess.call([r'steam.bat', gameID])\n",
    "    except TypeError:\n",
    "        print(\"GAME NOT FOUND\")\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search(command):\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def time():\n",
    "    e = datetime.datetime.now()\n",
    "    speak(\"The time is now: = %s:%s\" % (e.hour, e.minute))\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_do(command):\n",
    "    speak(\"THIS IS A TODO LIST\")\n",
    "    return False\n",
    "            \n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open(command):\n",
    "    if 'youtube' in command:\n",
    "        if \"search\" in command:\n",
    "            response = smartSearch(keyword=command)\n",
    "            say = f\"Here is what I found for {response}\"\n",
    "            speak(say)\n",
    "            driver = runWeb(web)\n",
    "            driver.get(f'https://www.youtube.com/results?search_query={response}')\n",
    "            driver.maximize_window()\n",
    "        else:\n",
    "            driver = runWeb(web)\n",
    "            driver.get(f'https://www.youtube.com/')\n",
    "            driver.maximize_window()\n",
    "\n",
    "    elif 'google' in command:\n",
    "        if 'search' in command:\n",
    "            response = smartSearch(keyword=command)\n",
    "            say = f\"Here is what I found for {response}\"\n",
    "            speak(say)\n",
    "            driver = runWeb(web)\n",
    "            driver.get(f'https://www.google.com/search?q={response}')\n",
    "            driver.maximize_window()\n",
    "        else:\n",
    "            driver = runWeb(web)\n",
    "            driver.get('https://www.google.com/')\n",
    "            driver.maximize_window()\n",
    "            \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close(command):\n",
    "\n",
    "    if \"exit app\" in command:\n",
    "        pg.hotkey('alt', 'f4')\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intents(command):\n",
    "    print(command)\n",
    "    completion = openai.Completion.create(\n",
    "        model=intents_model,\n",
    "        prompt=command,\n",
    "        temperature=0,\n",
    "        frequency_penalty=0.5,\n",
    "        max_tokens=5,\n",
    "        stop=[\"->\"]\n",
    "    )\n",
    "\n",
    "    cleanComplete = completion.choices[0].text.split()[0]\n",
    "    print(cleanComplete)\n",
    "    return cleanComplete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlCenter(command):\n",
    "\n",
    "    if command != \"\":\n",
    "        command = command.lower()\n",
    "        intent = intents(command + \"->\")\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    match intent:\n",
    "        case \"greeting\":\n",
    "            return greetings()\n",
    "        case \"play\":\n",
    "            return play(command)\n",
    "        case \"search\":\n",
    "            return search(command)\n",
    "        case \"todo\":\n",
    "            return to_do(command)\n",
    "        case \"time\":\n",
    "            return time()\n",
    "        case \"goodbye\":\n",
    "            return goodbye()\n",
    "        case \"open\":\n",
    "            return open(command)\n",
    "        case \"close\":\n",
    "            return close(command)\n",
    "        case _:\n",
    "            print(\"command not recognized, try again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'listenBack' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWaitTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thewa\\Desktop\\projects\\python\\virutal_assist\\idawV2.ipynb Cell 22\u001b[0m in \u001b[0;36mlistening\u001b[1;34m(tts)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     speak(\u001b[39m\"\u001b[39m\u001b[39mListening...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     audio \u001b[39m=\u001b[39m r3\u001b[39m.\u001b[39;49mlisten(source,timeout\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,phrase_time_limit\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mexcept\u001b[39;00m sr\u001b[39m.\u001b[39mWaitTimeoutError:\n",
      "File \u001b[1;32mc:\\Users\\thewa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:618\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m>\u001b[39m timeout:\n\u001b[1;32m--> 618\u001b[0m     \u001b[39mraise\u001b[39;00m WaitTimeoutError(\u001b[39m\"\u001b[39m\u001b[39mlistening timed out while waiting for phrase to start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    620\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mstream\u001b[39m.\u001b[39mread(source\u001b[39m.\u001b[39mCHUNK)\n",
      "\u001b[1;31mWaitTimeoutError\u001b[0m: listening timed out while waiting for phrase to start",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thewa\\Desktop\\projects\\python\\virutal_assist\\idawV2.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m speak(\u001b[39m\"\u001b[39m\u001b[39mI am Idaw. What can i help with today sir?\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     message \u001b[39m=\u001b[39m listening()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     done \u001b[39m=\u001b[39m controlCenter(message)\n",
      "\u001b[1;32mc:\\Users\\thewa\\Desktop\\projects\\python\\virutal_assist\\idawV2.ipynb Cell 22\u001b[0m in \u001b[0;36mlistening\u001b[1;34m(tts)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     audio \u001b[39m=\u001b[39m r3\u001b[39m.\u001b[39mlisten(source,timeout\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,phrase_time_limit\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mexcept\u001b[39;00m sr\u001b[39m.\u001b[39mWaitTimeoutError:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     listenBack \u001b[39m=\u001b[39m r3\u001b[39m.\u001b[39mlisten_in_background(source,listenBack)   \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thewa/Desktop/projects/python/virutal_assist/idawV2.ipynb#X30sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     voice \u001b[39m=\u001b[39m r3\u001b[39m.\u001b[39mrecognize_google(audio)  \u001b[39m# convert audio to text\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'listenBack' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "done = False\n",
    "\n",
    "speak(\"I am Idaw. What can i help with today sir?\")\n",
    "while not done:\n",
    "    message = listening()\n",
    "    done = controlCenter(message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa66cff0e5ae32d77d72462d7ae697218f766852b9c548e64c3db10232013247"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
